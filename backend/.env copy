# The name of LLM model to use.
# MODEL=gpt-4
LLM_MODEL=TheBloke/dolphin-2.1-mistral-7B-GGUF/dolphin-2.1-mistral-7b.Q4_K_S.gguf (from LMStudio)

# The OpenAI API key to use.
# OPENAI_API_KEY=

# For generating a connection URI, see https://docs.timescale.com/use-timescale/latest/services/create-a-service
# The PostgreSQL connection string.
CHROMA_HOST=localhost
CHROMA_PORT=6000

# The Llama Cloud API key.
LLAMA_CLOUD_API_KEY=

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

# Name of the embedding model to use.
EMBEDDING_MODEL=all-minilm

# LLM server URL.
LLM_SERVER_URL=http://localhost:1234/v1/chat/completions (LM studio)

EMBEDDINGS_SERVER_URL=http://localhost:11434/api/embeddings (Ollama)

# Dimension of the embedding model to use.
# EMBEDDING_DIM=

# Temperature for sampling from the model.
LLM_TEMPERATURE=0

# Maximum number of tokens to generate.
LLM_MAX_TOKENS=4096

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

CHROMA_COLLECTION_NAME=home_info

CHROMA_CHUNK_SIZE=200
CHUNK_OVERLAP = 50

# Custom system prompt.
# Example:
SYSTEM_PROMPT="You are a seasoned real estate agent who is keen to help people to find the best home. You are always truthful and detail oriented in your research. You are helping the user to research a home and finding out the nice features and major concerns." 


